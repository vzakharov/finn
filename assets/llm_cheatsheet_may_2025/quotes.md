Here’s the skinny on what the Reddit gang is saying about the newer models. Spoiler: there’s no consensus, just enthusiasm and grumbling in roughly equal measure.

---

## Jamba 1.6

> “It [beat Jamba 1.5 by a decent margin](https://www.reddit.com/r/LocalLLaMA/comments/1kk66rj/jamba_mini_16_actually_outperformed_gpt40_for_our). About 21% more of our QA outputs were grounded correctly and it was basically tied with GPT-4o in how well …"

> “It’s the [best model I’ve tried so far for RP](https://www.reddit.com/r/SillyTavernAI/comments/1jd8d1t/dont_sleep_on_ai21_jamba_16_large)—blows everything out of the water … it feels almost like it was specifically trained for RP.”

## Command A

> “Command a/command r can be used with a [free trial for 1000 responses PER EMAIL](https://www.reddit.com/r/SillyTavernAI/comments/1jmb0fk/just_got_safety_filters_from_anthropic_i_need/)! so basically limitless.”

## DeepSeek V3

> "[Deepseek with the right settings … can be very good](https://www.reddit.com/r/SillyTavernAI/comments/1jmb0fk/just_got_safety_filters_from_anthropic_i_need/), much better than anything else I’ve used, besides the hungriest of wallet eaters. It’s also very high in rankings for creative writing.”

> “Deepseek is the [state of the art right now in terms of performance and output](https://news.ycombinator.com/item?id=42890709). It’s really fast. The way it 'explains’ how it’s thinking is remarkable.”

> “It’s [not cheaper than Deepseek V3.1](https://news.ycombinator.com/item?id=43920132), though, and Deepseek outperforms on nearly everything. And only between 1–3× the throughput based on the openrouter metrics …"

## Gemini 2.5 Pro

> “I find [Gemini 2.5 Pro to be slightly better at coding than Grok 3](https://www.reddit.com/r/ArtificialInteligence/comments/1jyizj3/gemini_25_pro_is_by_far_my_favourite_coding_model). However, Grok is not as good at understanding user intent which really brings the whole experience down for me.”

> “THIS IS ABSURD! [GEMINI 2.5 FLASH IS GIVING BETTER, MORE DETAILED, AND SMARTER ANSWERS THAN GEMINI 2.5 PRO](https://www.reddit.com/r/Bard/comments/1kk00zr/google_what_have_you_done_to_gemini_25_pro/) … GEMINI 2.5 PRO IS LESS COMPETENT THAN GEMINI 2.5 FLASH ON TASKS THAT DON’T REQUIRE CODE. THIS IS OUTRAGEOUS!”

> “After the update, [the model appears to have regressed to 1.5 Pro’s level](https://www.reddit.com/r/Bard/comments/1kk00zr/google_what_have_you_done_to_gemini_25_pro/) … the flash version performs better for text creation, which I find extremely frustrating :("

## Llama 4 Maverick

> "[Llama 4 Maverick is the most efficient](https://www.reddit.com/r/LLMDevs/comments/1jzhc3x/llama_4_received_so_much_hate_but_it_actually/) and provide better result than any LLM in the current time (again, judging from my agent project only)."

> "[Llama 4 is a base model, 2.5 Pro is a reasoning model](https://www.reddit.com/r/singularity/comments/1jscj37/llama_4_vs_gemini_25_pro_benchmarks/), that’s just not a fair comparison.”

> "[Inference cost of Llama4 on openrouter is 10 times cheaper](https://www.reddit.com/r/LLMDevs/comments/1jzhc3x/llama_4_received_so_much_hate_but_it_actually/)."

## GPT-4.1

> “I fine-tuned GPT 4.1 earlier today and achieved an ROC-AUC of 0.94. [This is a game changer](https://www.reddit.com/r/LocalLLaMA/comments/1k25suh/gpt_41_is_a_game_changer/); it essentially 'solves’ my particular class of problems. I have to get rid of an entire Llama-based RL pipeline I literally just built over the past month.”

---

No holy grail here—just a buffet of strengths, weaknesses, and fiercely argued turf wars. Pick your poison!